{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6877710355414440864\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "#tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape x, y\n",
      "(506, 13) (506,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sagvd17\\Anaconda3\\envs\\jpytorch\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# data load\n",
    "#############\n",
    "\n",
    "# path = './data.csv'\n",
    "path = ''\n",
    "#data = pd.read_csv(path)\n",
    "\n",
    "# target(y) column\n",
    "target = '' \n",
    "\n",
    "# classification = 0, Regression = 1\n",
    "is_regrssion = 1\n",
    "\n",
    "#x = data.drop(target,axis=1)\n",
    "#y = data[target]\n",
    "\n",
    "##### test iris #####\n",
    "from sklearn.datasets import load_iris \n",
    "data = load_iris()\n",
    "x = data.data\n",
    "y = data.target\n",
    "##### test iris #####\n",
    "#### test boston ####\n",
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "x = data.data\n",
    "y = data.target\n",
    "#### test boston ####\n",
    "print('shape x, y')\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size 354\n",
      "test_size 152\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# data split\n",
    "#############\n",
    "test_size=.3\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=test_size,random_state=1)\n",
    "print('train_size',len(x_train))\n",
    "print('test_size',len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape x,y  (354, 13) (354,)\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# pre_propessor\n",
    "#############\n",
    "\n",
    "# default\n",
    "print('shape x,y ',x_train.shape,y_train.shape)\n",
    "if is_regrssion == 0:\n",
    "    print('y_train unique',np.unique(y_train))\n",
    "if x.shape > 2:\n",
    "    #x_shape=x_train.shape[1:-1]\n",
    "    pass\n",
    "else:\n",
    "    x_shape = x_train.shape[-1]\n",
    "y_shape = len(np.unique(y_train))\n",
    "dense_act = 'linear'\n",
    "loss_func = 'mse'\n",
    "mets = ['mae']\n",
    "\n",
    "if is_regrssion == 0:\n",
    "    # if classification\n",
    "    mets = ['acc']\n",
    "    dense_act = 'softmax'\n",
    "    \n",
    "    if len(np.unique(y_train)) > 2:\n",
    "        # when datset need one-hot-encoding\n",
    "        y_train = to_categorical(y_train)\n",
    "        #y_test = to_categorical(y_test)\n",
    "        loss_func = 'categorical_crossentropy'\n",
    "\n",
    "        print('y one-hot-encoded')\n",
    "        print(' y unique',np.unique(y_train))\n",
    "    else:\n",
    "        loss_func = 'binary_crossentropy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                896       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 196)               3332      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,892\n",
      "Trainable params: 7,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# Modeling\n",
    "###########\n",
    "# 1. clear session #\n",
    "keras.backend.clear_session()\n",
    "# 2. model set\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# epochs\n",
    "epochs = 500\n",
    "\n",
    "# 3. layer set \n",
    "model.add( keras.layers.Input(shape=x_shape) )\n",
    "model.add( keras.layers.Dense(64,activation='relu') )\n",
    "model.add( keras.layers.Dense(32,activation='relu') )\n",
    "model.add( keras.layers.Dense(32,activation='relu') )\n",
    "model.add( keras.layers.Dense(16,activation='relu') )\n",
    "model.add( keras.layers.Dense(y_shape, activation=dense_act) )\n",
    "\n",
    "\n",
    "# 4. compile model #\n",
    "model.compile(loss=loss_func,metrics=mets,optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 1s 2ms/step - loss: 552.5679 - mae: 21.2477\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 448.0391 - mae: 17.7488\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 315.4824 - mae: 13.9285\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 197.6788 - mae: 10.5872\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 120.6938 - mae: 7.9675\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 88.2636 - mae: 7.0015\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 70.4717 - mae: 6.1338\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.1353 - mae: 5.5650\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 61.1071 - mae: 5.6967\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 58.2040 - mae: 5.5563\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 56.7273 - mae: 5.2542\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 56.0252 - mae: 5.1714\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 56.2314 - mae: 5.2946\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 54.8647 - mae: 5.2054\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 54.1439 - mae: 4.9820\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 58.4325 - mae: 5.6565\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 54.4432 - mae: 5.0167\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 52.6604 - mae: 5.1236\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 52.0721 - mae: 4.9945\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 51.0153 - mae: 5.0238\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 50.2113 - mae: 4.8766\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 49.9995 - mae: 4.9711\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 50.2950 - mae: 5.0682\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 49.4135 - mae: 4.8259\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 52.4669 - mae: 4.9910\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 48.6889 - mae: 4.9368\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 47.8201 - mae: 4.7743\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 47.5420 - mae: 4.7104\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 46.7267 - mae: 4.6912\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 44.9467 - mae: 4.7671\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 46.8188 - mae: 4.6857\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 45.1756 - mae: 4.5334\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 44.7228 - mae: 4.7007\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 42.4199 - mae: 4.5751\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.9535 - mae: 4.4344\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 41.2694 - mae: 4.4444\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 50.1244 - mae: 5.1023\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 40.7993 - mae: 4.5486\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 42.7657 - mae: 4.7692\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.7344 - mae: 4.6286\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 39.0989 - mae: 4.3652\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 38.7602 - mae: 4.4218\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 36.8510 - mae: 4.2114\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 38.6884 - mae: 4.3503\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 40.1127 - mae: 4.5623\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.8347 - mae: 4.3252\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.2407 - mae: 4.2272\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 35.5576 - mae: 4.3518\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.8792 - mae: 4.1959\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.7075 - mae: 4.0489\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.5365 - mae: 4.1812\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.3539 - mae: 4.2906\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 35.6592 - mae: 4.2121\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.4578 - mae: 4.2518\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.0845 - mae: 4.1929\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9629 - mae: 4.2907\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.5304 - mae: 4.0832\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.4388 - mae: 3.9545\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.3544 - mae: 3.9454\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.7251 - mae: 3.8303\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.6041 - mae: 3.8608\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.0687 - mae: 4.1997\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.1150 - mae: 3.8271\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.6255 - mae: 3.8843\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.2094 - mae: 3.8041\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.5212 - mae: 3.8806\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.6164 - mae: 3.8055\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.7905 - mae: 3.7430\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.5768 - mae: 3.7925\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 30.0217 - mae: 4.0040\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.3391 - mae: 3.7579\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.8895 - mae: 3.7008\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.0930 - mae: 4.0071\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.6786 - mae: 3.9202\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.7635 - mae: 3.6857\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.4958 - mae: 3.6427\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.8598 - mae: 3.7326\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.2508 - mae: 4.0020\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.5157 - mae: 3.6212\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 22.1496 - mae: 3.5903\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1330 - mae: 3.5518\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 84.3574 - mae: 7.1500\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 53.9269 - mae: 5.7326\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.5723 - mae: 4.2808\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.7324 - mae: 3.9082\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.4780 - mae: 3.9799\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.3622 - mae: 4.2984\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.7185 - mae: 3.7157\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.2947 - mae: 3.6475\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.7700 - mae: 3.5959\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.0800 - mae: 3.6135\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 49.5932 - mae: 5.4817\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.1414 - mae: 4.5094\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.3080 - mae: 3.7755\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.8881 - mae: 3.7448\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.8494 - mae: 3.6190\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.3489 - mae: 3.6053\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1460 - mae: 3.6214\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.2692 - mae: 3.5219\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.3772 - mae: 3.5337\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1334 - mae: 3.5291\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.7915 - mae: 3.5048\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.5003 - mae: 3.4640\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.0201 - mae: 3.4621\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.5283 - mae: 3.4730\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.3264 - mae: 3.3895\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.6554 - mae: 3.4675\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.1731 - mae: 3.3603\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.5524 - mae: 3.7508\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.3561 - mae: 3.5064\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.4376 - mae: 3.4872\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.6552 - mae: 3.3269\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.0617 - mae: 3.2975\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.8564 - mae: 3.3679\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.1264 - mae: 3.3581\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.0644 - mae: 3.2537\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.3197 - mae: 3.2769\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.4616 - mae: 3.2767\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.0391 - mae: 3.6895\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.3299 - mae: 3.4966\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.1191 - mae: 3.3916\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.4735 - mae: 3.2814\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.1030 - mae: 3.4006\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.9622 - mae: 3.9345\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 24.6301 - mae: 3.8705\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.0256 - mae: 3.4633\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.8856 - mae: 3.7146\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.7942 - mae: 3.4939\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.2217 - mae: 3.3868\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.3477 - mae: 3.2479\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.8644 - mae: 3.3596\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.5943 - mae: 3.3296\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.0036 - mae: 3.1494\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.3892 - mae: 3.5196\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.9729 - mae: 3.2264\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.1641 - mae: 3.3632\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.5016 - mae: 3.4603\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.0515 - mae: 3.1397\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.1059 - mae: 3.1646\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.1325 - mae: 3.1106\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.7723 - mae: 3.5284\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.0721 - mae: 3.2348\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.0538 - mae: 3.1671\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.9171 - mae: 3.0862\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.7347 - mae: 3.4089\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 39.8607 - mae: 4.3583\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 36.8021 - mae: 4.1927\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.7490 - mae: 3.7344\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.9697 - mae: 3.5051\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.2505 - mae: 3.5295\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.1003 - mae: 3.3755\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.8273 - mae: 3.3897\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.1578 - mae: 3.2958\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.3752 - mae: 3.4046\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.7783 - mae: 3.3077\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.4946 - mae: 3.1683\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.1406 - mae: 3.2791\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.6932 - mae: 3.7607\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.1306 - mae: 3.3322\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.7628 - mae: 3.1463\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.1319 - mae: 3.6462\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.0991 - mae: 3.2066\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.0131 - mae: 3.0957\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.8200 - mae: 3.7130\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.2330 - mae: 4.3356\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.9704 - mae: 4.0504\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.5347 - mae: 3.8047\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.7125 - mae: 3.3161\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.6967 - mae: 3.4226\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.3435 - mae: 3.5863\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.4318 - mae: 3.2064\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.2885 - mae: 3.4431\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.0115 - mae: 3.2252\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.5115 - mae: 3.1222\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.8469 - mae: 3.0648\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.5282 - mae: 3.0387\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.4742 - mae: 3.0995\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.6651 - mae: 3.0666\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.6830 - mae: 3.0827\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.3629 - mae: 3.0001\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.2472 - mae: 3.0092\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.4205 - mae: 3.3390\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.5708 - mae: 3.2783\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.7078 - mae: 3.1176\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.3008 - mae: 3.0733\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.5450 - mae: 3.2920\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.4712 - mae: 3.2606\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.3130 - mae: 3.3835\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.2434 - mae: 3.1557\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.7331 - mae: 3.1310\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.2235 - mae: 3.1307\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.4910 - mae: 3.1377\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.5752 - mae: 3.1130\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.1543 - mae: 3.1593\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 18.8798 - mae: 3.1122\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.9257 - mae: 3.1370\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.0667 - mae: 3.0546\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.0583 - mae: 3.0077\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.0132 - mae: 2.9561\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.4077 - mae: 2.9196\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.9201 - mae: 2.9763\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.8778 - mae: 2.9726\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 17.1962 - mae: 2.9910\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.5672 - mae: 3.0652\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.7904 - mae: 2.9216\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.4346 - mae: 3.0382\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.7048 - mae: 2.9375\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.0377 - mae: 3.1156\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.5062 - mae: 3.1942\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.5236 - mae: 3.1099\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.0445 - mae: 3.3341\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.3624 - mae: 3.4552\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.5882 - mae: 2.9981\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.9963 - mae: 3.0344\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 17.7896 - mae: 3.0197\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.8857 - mae: 3.0337\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.8090 - mae: 3.0838\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.2658 - mae: 3.1042\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.5689 - mae: 3.0950\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.1101 - mae: 2.9619\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.0512 - mae: 2.9658\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.4789 - mae: 2.9898\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.0253 - mae: 3.0382\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.9758 - mae: 3.4894\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.8615 - mae: 3.2661\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 17.5902 - mae: 3.0780\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.8542 - mae: 2.9899\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.7361 - mae: 2.8577\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.2944 - mae: 3.0322\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.4358 - mae: 3.0327\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.5868 - mae: 3.1302\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.4485 - mae: 3.0759\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.5328 - mae: 3.1081\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.8901 - mae: 3.0783\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.1248 - mae: 2.9170\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.1459 - mae: 2.9456\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.6879 - mae: 2.9843\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.8147 - mae: 2.9875\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.6709 - mae: 2.9884\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 21.3300 - mae: 3.3845\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.9133 - mae: 3.1576\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.6960 - mae: 3.2083\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.8288 - mae: 3.3077\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.8629 - mae: 2.9676\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.0481 - mae: 2.9253\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.7021 - mae: 2.8479\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.4993 - mae: 3.0782\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.2885 - mae: 2.9340\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.1823 - mae: 3.1866\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.9235 - mae: 3.0553\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.8113 - mae: 2.9457\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.0932 - mae: 2.8970\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.5122 - mae: 2.9283\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.5626 - mae: 2.8986\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.7346 - mae: 3.5920\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.0110 - mae: 2.9560\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.1779 - mae: 2.9519\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.4476 - mae: 3.4542\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.3045 - mae: 3.4140\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 38.3794 - mae: 4.3369\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.8364 - mae: 3.5239\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.9948 - mae: 3.3923\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.2959 - mae: 3.0509\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.6584 - mae: 3.0353\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.7889 - mae: 2.8666\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.8532 - mae: 3.0994\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.4619 - mae: 2.9597\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.9367 - mae: 3.1434\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.7500 - mae: 3.5733\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.2982 - mae: 4.5789\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.6468 - mae: 3.4966\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.8785 - mae: 3.3374\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.4448 - mae: 2.8933\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.6608 - mae: 2.8231\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.4378 - mae: 2.8510\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.0535 - mae: 2.9891\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.9305 - mae: 3.0844\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.4374 - mae: 3.0502\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.1565 - mae: 2.9832\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.5682 - mae: 2.8934\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 14.7966 - mae: 2.8759\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.1024 - mae: 3.0260\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.6825 - mae: 2.8578\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.2747 - mae: 2.8794\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.4480 - mae: 2.9173\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.4121 - mae: 2.9446\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.6449 - mae: 3.5318\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.5066 - mae: 3.4562\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.8481 - mae: 3.3673\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 44.4500 - mae: 4.8208\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.5407 - mae: 3.8580\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 43.5151 - mae: 4.6225\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 31.8898 - mae: 4.0208\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.6205 - mae: 3.5468\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.0448 - mae: 3.4580\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.2940 - mae: 3.0625\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.8942 - mae: 3.1800\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.9565 - mae: 3.0913\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.1749 - mae: 2.9695\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.0398 - mae: 2.9109\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.8548 - mae: 2.8428\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.4840 - mae: 3.6579\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 19.4283 - mae: 3.2181\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.1614 - mae: 2.9257\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.5239 - mae: 3.0189\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.6821 - mae: 2.8595\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.5280 - mae: 2.9839\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.6214 - mae: 2.8461\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.3911 - mae: 2.7885\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 49.8738 - mae: 5.0708\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.7003 - mae: 3.9194\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.7607 - mae: 3.1373\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.7128 - mae: 3.0723\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.9554 - mae: 3.1605\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.6163 - mae: 3.0871\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.4596 - mae: 3.2235\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.5971 - mae: 2.8664\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.0530 - mae: 2.8086\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.3320 - mae: 2.7943\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.1325 - mae: 2.7946\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 18.5222 - mae: 3.1205\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.2219 - mae: 2.8343\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.7894 - mae: 2.8497\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 14.6729 - mae: 2.7501\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.8990 - mae: 2.8046\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.5862 - mae: 2.8501\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.1630 - mae: 2.7722\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.5871 - mae: 2.7385\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.0299 - mae: 2.9012\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.2568 - mae: 2.8926\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.7395 - mae: 2.9883\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 42.7437 - mae: 4.5358\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.2131 - mae: 3.6966\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.0262 - mae: 3.2262\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.2552 - mae: 2.9711\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.7031 - mae: 3.4066\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.4960 - mae: 3.2901\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.9390 - mae: 2.9061\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.2269 - mae: 2.8558\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.4370 - mae: 2.7874\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.6636 - mae: 2.8242\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.3701 - mae: 2.8309\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.6372 - mae: 2.8413\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.0742 - mae: 2.7774\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.5363 - mae: 4.0327\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.2316 - mae: 3.4425\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.8731 - mae: 3.1250\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.6854 - mae: 2.9972\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.3081 - mae: 2.8503\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.2120 - mae: 2.8225\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 16.5507 - mae: 2.9456\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.7384 - mae: 2.7137\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.9709 - mae: 2.8578\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 14.4673 - mae: 2.7495\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.4567 - mae: 2.7311\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.0561 - mae: 2.6983\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.5738 - mae: 2.7850\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.9433 - mae: 2.9825\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.3832 - mae: 2.7871\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 31.0841 - mae: 4.0569\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.6583 - mae: 3.5541\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.1042 - mae: 2.9830\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 30.2150 - mae: 3.7221\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 30.5533 - mae: 4.3868\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.3397 - mae: 3.3077\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.7692 - mae: 2.8970\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.9208 - mae: 3.0121\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.6653 - mae: 2.7849\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.3586 - mae: 2.7172\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.4371 - mae: 2.8806\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.2239 - mae: 2.6928\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.8098 - mae: 2.7443\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.0174 - mae: 2.7796\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 14.7422 - mae: 2.8091\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.8515 - mae: 3.0364\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.3624 - mae: 2.7058\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.5545 - mae: 2.8146\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.4770 - mae: 2.9479\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 14.9364 - mae: 2.8000\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.2305 - mae: 3.1600\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.4147 - mae: 3.2954\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.2023 - mae: 3.8668\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.3476 - mae: 3.3457\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.0694 - mae: 2.9359\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.4490 - mae: 2.8257\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.5081 - mae: 3.0075\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.8431 - mae: 2.8465\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.0481 - mae: 2.6832\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.5239 - mae: 2.8024\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.8843 - mae: 3.0065\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.7506 - mae: 2.9132\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.4508 - mae: 2.8784\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.9513 - mae: 2.7615\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.0574 - mae: 3.0216\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.5412 - mae: 3.0289\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.9059 - mae: 2.8340\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.5057 - mae: 2.8008\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.4508 - mae: 2.8416\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.7030 - mae: 2.8320\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.1545 - mae: 2.7375\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.7354 - mae: 2.6414\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.6386 - mae: 2.6981\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 13.6625 - mae: 2.6934\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.4112 - mae: 2.6692\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.3000 - mae: 2.7449\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.5166 - mae: 2.6384\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 14.7382 - mae: 2.7609\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.9419 - mae: 2.7274\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.8383 - mae: 2.8441\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 13.9884 - mae: 2.7734\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.3435 - mae: 2.7055\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.5987 - mae: 2.8557\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.9370 - mae: 2.8329\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.8895 - mae: 3.1236\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.5501 - mae: 2.8077\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.1127 - mae: 2.7899\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.4445 - mae: 3.2513\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.3800 - mae: 2.9905\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.6202 - mae: 2.9219\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.3305 - mae: 3.1185\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.4162 - mae: 3.1036\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.2535 - mae: 2.8033\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.0128 - mae: 2.7433\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.8886 - mae: 2.7509\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 13.6923 - mae: 2.6964\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.9401 - mae: 2.6782\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.1929 - mae: 2.6163\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.2583 - mae: 2.7928\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.4459 - mae: 2.6843\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.3866 - mae: 2.6014\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 14.7910 - mae: 2.6995\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.7366 - mae: 2.6552\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 17.6112 - mae: 3.0021\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.0458 - mae: 2.7866\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.5915 - mae: 3.1145\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.6460 - mae: 3.2041\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.0436 - mae: 3.0322\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 14.7213 - mae: 2.7366\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.2010 - mae: 2.6764\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.5190 - mae: 2.6037\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 13.4131 - mae: 2.6996\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.8258 - mae: 2.6392\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 13.0800 - mae: 2.6065\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.3589 - mae: 2.6584\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.3849 - mae: 2.6385\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.0966 - mae: 2.6459\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 14.0938 - mae: 2.7575\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.3983 - mae: 2.6158\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.9421 - mae: 2.9779\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.0958 - mae: 2.9980\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.1209 - mae: 2.8204\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.5909 - mae: 2.7052\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 15.3566 - mae: 2.8025\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.2955 - mae: 2.8353\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.2715 - mae: 2.6282\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 13.6210 - mae: 2.5996\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 12.8780 - mae: 2.5831\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.7447 - mae: 2.6706\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 14.1511 - mae: 2.8026\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.5982 - mae: 2.7312\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 13.9083 - mae: 2.7240\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.3946 - mae: 3.9894\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.0473 - mae: 3.8448\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.8081 - mae: 3.3922\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.5427 - mae: 3.2051\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.7876 - mae: 2.9058\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.5576 - mae: 2.8910\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.2249 - mae: 3.0106\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.7502 - mae: 2.9742\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.8615 - mae: 2.8748\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.6899 - mae: 3.0088\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.0302 - mae: 2.6955\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.6122 - mae: 2.7040\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.5134 - mae: 2.9739\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.1092 - mae: 2.9454\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.8862 - mae: 2.6720\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 14.8164 - mae: 2.7425\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.5051 - mae: 2.7491\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.1476 - mae: 2.7309\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.0268 - mae: 2.6819\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.4327 - mae: 2.7077\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.3925 - mae: 2.6652\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.9359 - mae: 2.8158\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.7914 - mae: 2.9158\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 16.2428 - mae: 2.8801\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 17.2072 - mae: 2.9340\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.6791 - mae: 2.6835\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.5570 - mae: 2.5897\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.5125 - mae: 2.5724\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.2298 - mae: 2.5980\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.0993 - mae: 2.6362\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.7303 - mae: 3.2073\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.6535 - mae: 2.9375\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 16.6177 - mae: 2.9511\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 15.5935 - mae: 2.7865\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.1875 - mae: 2.6585\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 14.6370 - mae: 2.6867\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 13.4999 - mae: 2.5472\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.7272 - mae: 2.7049\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 13.8108 - mae: 2.6149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be62f14b88>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "[[32. 32. 32. ... 32. 32. 32.]\n",
      " [26. 26. 26. ... 26. 26. 26.]\n",
      " [19. 18. 19. ... 19. 19. 19.]\n",
      " ...\n",
      " [19. 18. 19. ... 19. 18. 19.]\n",
      " [30. 30. 30. ... 30. 30. 30.]\n",
      " [17. 17. 17. ... 17. 17. 17.]] 152\n",
      "[28.2 23.9 16.6 22.  20.8 23.  27.9 14.5 21.5 22.6 23.7 31.2 19.3 19.4\n",
      " 19.4 27.9 13.9 50.  24.1 14.6 16.2 15.6 23.8 25.  23.5  8.3 13.5 17.5\n",
      " 43.1 11.5 24.1 18.5 50.  12.6 19.8 24.5 14.9 36.2 11.9 19.1 22.6 20.7\n",
      " 30.1 13.3 14.6  8.4 50.  12.7 25.  18.6 29.8 22.2 28.7 23.8  8.1 22.2\n",
      "  6.3 22.1 17.5 48.3 16.7 26.6  8.5 14.5 23.7 37.2 41.7 16.5 21.7 22.7\n",
      " 23.  10.5 21.9 21.  20.4 21.8 50.  22.  23.3 37.3 18.  19.2 34.9 13.4\n",
      " 22.9 22.5 13.  24.6 18.3 18.1 23.9 50.  13.6 22.9 10.9 18.9 22.4 22.9\n",
      " 44.8 21.7 10.2 15.4 25.3 23.3  7.2 21.2 11.7 27.  29.6 26.5 43.5 23.6\n",
      " 11.  33.4 36.  36.4 19.  20.2 34.9 50.  19.3 14.9 26.6 19.9 24.8 21.2\n",
      " 23.9 20.6 23.1 28.  20.  23.1 25.   9.7 23.9 36.1 13.4 12.7 39.8 10.4\n",
      " 20.6 17.8 19.5 23.7 28.5 24.3 23.8 19.1 28.4 20.5 33.8 14.5] 152\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_preds = []\n",
    "correct = 0\n",
    "if is_regrssion == 0:\n",
    "    for idx, pred in enumerate(y_pred):\n",
    "        y_preds.append(np.argmax(pred))\n",
    "        y_preds=np.array(y_preds).reshape(-1)\n",
    "else:\n",
    "    y_preds=np.array(np.around(y_pred))\n",
    "#acc = correct/len(y_pred)\n",
    "#print(f'acc:{acc*100}%')\n",
    "\n",
    "print(y_preds,len(y_preds))\n",
    "print(y_test,len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2134deeb031d3043ee0562711738d1225b978d11603940a3a342e52f3e23eb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
